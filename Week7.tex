
% !TeX spellcheck = pt_BR
% !TEX encoding = UTF-8 Unicode

% Ver copyright.tex para direitos autorais e licença.

\clearpage
\section{A Lei dos Grandes Números}

Um dos principais tópicos da Probabilidade é a "lei dos grandes números".
Ela afirma que a soma de um grande número de variáveis independentes tende a se aproximar da esperança.
Mais precisamente, a média observada
$ \frac{X_1 + \dots + X_n}{n} $,
que é aleatória, se aproximará da média teórica
$ \E[ \frac{X_1 + \dots + X_n}{n} ] $,
que é determinística!

A manifestação mais simples desse fenômeno diz respeito às frequências relativas.
Imagine que executamos um experimento muitas vezes, sob as mesmas condições, e contamos quantas vezes resultou em sucesso e quantas vezes resultou em fracasso.
Tomando $ X_n $ como o indicador de que o $ n $-ésimo teste resultou em sucesso, a frequência relativa de sucesso é exatamente dada por
$ \frac{X_1 + \dots + X_n}{n} $.
Enquanto escrevia esse preâmbulo, os palestrantes simularam o lançamento de uma moeda justa um milhão de vezes e obtiveram "Cara" 499.947 vezes.
Repetindo o mesmo procedimento, eles obtiveram "Cara" 499.508 vezes, depois 500.318 vezes e, em seguida, 500.512 vezes.
Obviamente, algo está acontecendo aqui.
Conforme previsto pela lei dos grandes números, a frequência relativa sempre foi muito próxima da probabilidade de obter "Cara" em cada lançamento da moeda, que é exatamente $ \frac{1}{2} $.
Intuitivamente, tendemos a associar a probabilidade de sucesso à frequência relativa de sucessos, e essa associação está quase arraigada em nosso pensamento.

Mais genericamente, o resultado relevante de cada experimento não precisa ser $ 0 $ ou $ 1 $ para representar fracasso ou sucesso. Pode ser qualquer variável aleatória.
Antes de escrever este parágrafo, os palestrantes lançaram um dado 10 vezes, e a soma dos valores obtidos foi 38.
Repetindo o mesmo procedimento, eles obtiveram 33, 28, 37 e, finalmente, 43.
Não parece muito com essa soma estar bem concentrada perto de algum valor determinístico.
No entanto, as palestras prosseguiram com a simulação de 10.000 lançamentos do dado, e a soma dos resultados foi 35.082.
Repetindo esse procedimento, eles obtiveram uma soma de 34.769, depois 35.419 e, finalmente, 34.691.
Conforme previsto pela lei dos grandes números, quando o número de lançamentos dos dados era grande, a média observada estava sempre próxima da média teórica, dada por $ \E[X_1]=\frac{7}{2} $.

Na teoria da Probabilidade, a lei dos grandes números não é apenas uma história ou um fenômeno misterioso, é um teorema que pode ter muitas formulações diferentes. Aqui consideraremos a versão mais simples possível.

\begin{theorem}
[Lei dos Grandes Números]
\label{thm:lln}
Se $ X_1, X_2, X_3, \dots $ forem variáveis aleatórias discretas independentes duas a duas e com variância quadrática integrável, com a mesma média $ \mu $ e mesma variância $ \sigma^2 $, então, para todo $ a>0 $ e $ n \in \N $,
\[
\Pb\Big( \mu-a \leq \frac{X_1+\dots+X_n}{n} \leq \mu+a \Big)
\geq
1 - \frac{\sigma^2}{a^2\, n}
.
\]
\end{theorem}

A lei dos grandes números é comumente conhecida como a Lei dos Grandes Números.

Chamamos a atenção para o fato de que, não importa quão pequeno seja $ a $, essa probabilidade pode ser aproximada por $ 1 $, desde que escolhamos um valor grande o suficiente para $ n $ (é claro, se $ a $ for muito pequeno, precisaremos de um valor realmente muito grande para $ n $).

Nosso próximo objetivo é entender como tal estimativa de probabilidades surgiu. Até agora, usamos probabilidades para calcular esperanças e desvios padrão, e agora de repente estamos usando o desvio padrão para fazer estimativas extremamente interessantes sobre probabilidades!

Essa empreitada terá duas partes: entender qual é a variância da soma de muitas variáveis aleatórias e entender como a variância de uma variável aleatória fornece estimativas sobre a probabilidade de ela se desviar de sua média.

\clearpage
\section{Covariância}
\label{sec:covariância}

\subsection{Definição}

O que acontece com a variância quando adicionamos variáveis?

\begin{example}
Lance cinco moedas justas. Seja $X$ o número de "Cara" nos primeiros dois lançamentos de moedas, e $Y$ o número de "Cara" nos últimos três lançamentos de moedas. Seja $Z = X+Y$ o número total de "Cara" em todos os cinco lançamentos. Após cálculos (que omitimos), obtemos $ \V(X) = \frac{1}{2} $, $ \V(Y) = \frac{3}{4} $ e $ \V(Z) = \frac{5}{4} $. Neste caso, a relação $ \V(X+Y) = \V(X+Y) $ foi verificada. Isso é uma coincidência? Em quais condições essa relação é verificada?
\end{example}

\begin{example}
Suponha que $ X \sim \Bernoulli(\frac{1}{2}) $ e seja $ Y = X $. Neste caso, temos $ \V(X) = \frac{1}{4} $, $ \V(Y) = \frac{1}{4} $, $ \V(X+Y) = 1 $, então $ \V(X+Y) \ne \V(X+Y) $.
\end{example}

Para entender melhor o que acontece com $ \V(X+Y) $, expandimos:
\begin{align}
\V (X+Y)
&= \E [ ((X -\E [X])+(Y  -\E [Y]))^2 ] \\
&= \V (X) +\V (Y) + 2 \cdot \E [(X-\E [X] )(Y-\E [Y])].
\end{align}

\begin{definition}
[Covariância]
Suponha que $ X $ e $ Y $ são variáveis aleatórias discretas de variância quadrática integrável. Definimos a \emph{covariância de $ X $ e $ Y $} como
\[
\Cov(X,Y)
=
\E[ (X-\E[X])(Y-\E[Y]) ]
.
\]
\end{definition}

A partir dos cálculos anteriores, vemos que $ \V (X+Y) = \V(X)+\V(Y) $ se e somente se $ \Cov(X,Y)=0 $. Quando essa condição é satisfeita, dizemos que $ X $ e $ Y $ são \emph{não correlacionados}.

\subsection{Propriedades}
\label{sub:covproperties}

Vejamos as principais propriedades da covariância.
Trocando $ X $ e $ Y $, temos
\[
\Cov(X,Y)
=
\Cov(Y,X)
\]

Substituindo $ X $ no lugar de $ Y $, obtemos
\[
\Cov(X,X) = \V(X)
\]

\begin{proposition}
Suponha que $ X $, $ Y $ e $ Z $ são variáveis aleatórias discretas de variância quadrática integrável. Então
\[
\Cov(aX+bY,Z)
=
a\, \Cov(X,Z)
+
b\, 
\Cov(Y,Z)
\]
para todo $ a,b\in\R $.
\end{proposition}
\begin{proof}
Basta expandir e agrupar:
\begin{align}
\Cov(aX+bY,Z)
& =
\E[ ((aX+bY)-\E[aX+bY])(Z-\E[Z]) ]
\\
& =
\E[ (aX-\E[aX]+bY-\E[bY])(Z-\E[Z]) ]
\\
& =
\E[ (aX-\E[aX])(Z-\E[Z])+(bY-\E[bY])(Z-\E[Z]) ]
\\
& =
a\, \E[ (X-\E[X])(Z-\E[Z])]+b\,  \E[(Y-\E[Y])(Z-\E[Z]) ]
\\
& =
a\, \Cov(X,Z)
+
b\, 
\Cov(Y,Z),
\end{align}
provando a identidade.
\end{proof}

\begin{corollary}
Suponha que $ X_1, \dots, X_n, Y_1, \dots, Y_m $ são variáveis aleatórias discretas de variância quadrática integrável. Então
\[
\Cov \Big(\sum_{j=1}^n a_j X_j \,,\, \sum_{k=1}^m b_k Y_k\Big)
=
\sum_{j=1}^n \sum_{k=1}^m a_j b_k \Cov( X_j , Y_k )
\]
para todo $ a_1, \dots, a_n, b_1, \dots, b_m \in \R $.
\end{corollary}
\begin{proof}
Usando a proposição anterior repetidamente e a simetria,
\begin{align}
\Cov\Big(\sum_{j=1}^n a_j X_j \,,\, \sum_{k=1}^m b_j Y_j\Big)
& =
\sum_{j=1}^n a_j \Cov\Big( X_j , \sum_{k=1}^m  b_j Y_j\Big)
\\
& =
\sum_{j=1}^n a_j \Cov\Big( \sum_{k=1}^m  b_j Y_j , X_j\Big)
\\
& =
\sum_{j=1}^n \sum_{k=1}^m a_j b_k \Cov( Y_j, X_j)
\\
& =
\sum_{j=1}^n \sum_{k=1}^m a_j b_k \Cov( X_j , Y_j)
,
\end{align}
o que prova a identidade declarada.
\end{proof}

\begin{corollary}
Sejam $ X_1, \dots, X_n $ variáveis aleatórias discretas de variância quadrática integrável. Então
\[
\V\Big(\sum_{k=1}^n X_k\Big)
=
\sum_{k=1}^n \V(X_k) + 2 \sum_{1 \leq j<k \leq n} \Cov(X_j,X_k)
\]
\end{corollary}
\begin{proof}
Usando as propriedades anteriores,
\begin{align}
\V\Big(\sum_{k=1}^n X_k\Big)
& =
\Cov\Big(\sum_{j=1}^n X_j, \sum_{k=1}^n X_k\Big)
\\
& =
\sum_{j=1}^n \sum_{k=1}^n \Cov( X_j, X_k)
\\
& =
\sum_{k=1}^n \Cov( X_k, X_k)
+
\sum_{j\ne k} \Cov( X_j, X_k)
\\
& =
\sum_{k=1}^n \V( X_k)
+
2
\sum_{1 \leq j < k \leq n} \Cov( X_j, X_k)
.
\qedhere
\end{align}
\end{proof}

\begin{definition}
\label{def:uncorrelated}
Dizemos que uma coleção de variáveis aleatórias discretas de variância quadrática integrável $ X_1, X_2, X_3, \dots $ é \emph{não correlacionada} se $ \Cov (X_j, X_k) = 0 $ para cada $ j \ne k $.
\end{definition}

\begin{corollary}
\label{cor:uncorrelated}
Se $ X_1, \dots, X_n $ são variáveis aleatórias discretas não correlacionadas, então
\[
\V\Big(\sum_{k=1}^n X_k\Big)
=
\sum_{k=1}^n \V(X_k)
.
\]
\end{corollary}
\begin{proof}
Aplique a fórmula anterior e observe que a covariância entre termos diferentes é zero.
\end{proof}

Isso nos dá a "lei da raiz quadrada": se $ X_1, \dots, X_n $ são variáveis aleatórias discretas não correlacionadas com a mesma média $ \mu $ e variância $ \sigma^2 $, então
\[
\E[\tfrac{X_1 + \dots + X_n}{n} ] = \mu
\qquad
\text{ e }
\qquad
\sigma(\tfrac{X_1 + \dots + X_n}{n}) = \tfrac{\sigma}{\sqrt{n}}
.
\]

Isso começa a explicar por que a lei das médias emerge quando somamos muitas variáveis aleatórias.

\subsection{Somas de variáveis independentes duas a duas}

Talvez uma expressão mais conveniente para a covariância:
\[
\Cov(X, Y) = \E[XY] - \E[X] \cdot \E[Y]
.
\]
Se $X$ e $Y$ são independentes, então, pelo Teorema~\ref{thm:fubini}, $ \Cov(X, Y) = 0 $.

\begin{corollary}
\label{cor:varsumind}
Se $X_1, \dots, X_n $ são variáveis aleatórias discretas de variância quadrática integrável independentes duas a duas, então
\[
\V\Big(\sum_{k=1}^n X_k\Big)
=
\sum_{k=1}^n \V(X_k)
.
\]
\end{corollary}

Pela observação anterior, uma família de variáveis aleatórias discretas independentes duas a duas também é não correlacionada.


\clearpage
\section{Desigualdade de Chebyshev}

Agora veremos como a média e o desvio padrão de uma variável aleatória nos permitem fazer algumas estimativas sobre probabilidades envolvendo a variável aleatória.

\subsection{Desigualdade de Markov}

Para chegarmos lá, começamos com algo mais modesto: a Desigualdade de Markov.
Ela nos permite dizer algo sobre a distribuição de uma variável aleatória com base no conhecimento de sua expectativa.

\begin{theorem}
[Desigualdade de Markov]
Seja $X$ uma variável aleatória discreta integrável não negativa.
Então,
\[
\Pb( X > x ) \leq \frac{\E[X]}{x}
\]
para todo $x>0$.
\end{theorem}
\begin{proof}
Fixe~$x > 0$. Defina a variável aleatória
\begin{align}
 Y:=\begin{cases} x&\text{se } X \ge x;\\ 0&\text{caso contrário.} \end{cases} 
 \end{align}
Temos que~$X \ge Y$, porque:
\begin{itemize}
\item se~$X \ge x$, então~$Y = x$, então~$X \ge Y$;
\item se~$X \in [0,x)$, então~$Y = 0$, então~$X \ge Y$.
\end{itemize}
Isso também nos dá~$\E[X] \ge \E[Y]$. Em seguida, observe que~$Y$ é uma variável aleatória discreta (ela assume apenas os valores 0 e~$x$) com
\begin{align}
 p_Y(x) = \Pb(X \ge x),\qquad p_Y(0) = \Pb(X < x).
 \end{align}
Portanto,
\[\E[X] \ge \E[Y] = 0 \cdot p_Y(0) + x\cdot p_Y(x) = x\cdot p_Y(x) = x\cdot \Pb(X \ge x).\]
Rearranjando isso, obtemos a desigualdade desejada.
\end{proof}

\begin{example}
Suponha que uma empresa produza em média 50 itens por semana. Você pode estimar a probabilidade de que a produção de uma semana específica exceda 75 itens? 
Seja $X$ o número de itens que a empresa produz a cada semana. Pela afirmação, sabemos que $X \geq 0$ e $\E[X]=50$. Portanto, as premissas da Desigualdade de Markov são satisfeitas e podemos deduzir uma estimativa sobre a probabilidade solicitada, que é
$\Pb(X \geq 75)$. 
Portanto,
\begin{equation}
\Pb(X\geq 75) \leq \frac{\E[X]}{75} = \frac{50}{75}= \frac{2}{3} \,.
\end{equation}
\end{example}

É interessante notar que a Desigualdade de Markov nem sempre fornece uma limitação útil. De fato, se~$X$ for uma variável aleatória não negativa com expectativa igual a~$\mu$, e~$x \in (0,\mu]$, então na desigualdade
\[\Pb(X \ge x) \le \frac{\mu}{x},\]
o lado direito é maior que 1, então a limitação apenas nos diz que a probabilidade é menor ou igual a 1, mas já sabíamos disso!

\subsection{Desigualdade de Chebyshev}
\label{sub:chebyshev}

Enquanto a Desigualdade de Markov fornece uma limitação sobre a probabilidade de uma variável aleatória ser grande, a Desigualdade de Chebyshev fornece uma limitação sobre a probabilidade de uma variável aleatória estar longe de sua expectativa.

\begin{theorem}
[Desigualdade de Chebyshev]
Seja~$X$ uma variável aleatória discreta de variância quadrática integrável.
Então,
\[
\Pb(|X - \E[X]| \ge a) \le \frac{\V (X)}{a^2}
\]
para todo $ a>0 $.
\end{theorem}
É importante destacar que aqui não fazemos suposições quanto ao sinal de~$X$.
\begin{proof}
Seja $ a>0 $.
Defina $Y:= \left(X-\E[X]\right)^2$. Portanto,~$Y$ é não negativa e
\[
\E[Y] = \E\left[\left(X-\E[X]\right)^2\right] = \V (X).
\]
Em particular,~$Y$ é integrável.
A seguir, observe que os seguintes eventos são os mesmos:
\[
\{|X-\E[X]| \ge a\} = \{(X-\E[X])^2 \ge a^2\} = \{Y \ge a^2\}.
\]
Portanto, pela Desigualdade de Markov, temos
\[
\Pb(|X -\E[X]| \ge a) = \Pb(Y \ge a^2) \le \frac{\E[Y]}{a^2} = \frac{\V (X)}{a^2}
.
\]
Isso conclui a prova do teorema.
\end{proof}

\begin{example}
Suponha que $ \E[X] = 10 $ e $ \sigma(X)=2 $.
Vamos encontrar uma estimativa da probabilidade de que $ 6 \leq X \leq 14 $.
Tomando $ x=4 $ na Desigualdade de Chebyshev,
\[
\Pb( 6 \leq X \leq 14 )
\geq
\Pb( 6 < X < 14 )
=
1 - \Pb( |X-\E[X]| \geq 4 )
\geq
1 - \frac{2^2}{4^2}
= \frac{3}{4}
.
\]
\end{example}

\subsection{Prova da lei das médias}
\label{sub:prooflln}

Lembrando que $ X_1, X_2, X_3, \dots $ são variáveis aleatórias discretas de variância quadrática integrável independentes duas a duas com a mesma média $ \mu $ e mesma variância $ \sigma^2 $.

Queremos mostrar que, para todo $ a>0 $ e $ n \in \N $,
\[
\Pb\Big( \mu-a \leq \frac{X_1+\dots+X_n}{n} \leq \mu+a \Big)
\geq
1 - \frac{\sigma^2}{a^2\, n}
.
\]

Usando a linearidade da expectativa e o fato de que todos os $ X_k $ têm a mesma média $ \mu $,
\[
\E
\Big[ \frac{X_1+\dots+X_n}{n} \Big]
=
\frac{1}{n}
\E\big[ X_1+\dots+X_n \big]
=
\frac{1}{n}
\cdot
\big(
\E[ X_1 ]
+\dots+
\E[ X_n ]
\big)
= \mu.
\]
Usando o Corolário~\ref{cor:varsumind} e o fato de que todos os $ X_k $ têm a mesma variância $ \sigma^2 $,
\begin{align}
\V \Big( \frac{X_1+\dots+X_n}{n} \Big)
&=
\frac{1}{n^2} \V \big( X_1+\dots+X_n \Big)
\\
&=
\frac{1}{n^2} \big( \V (X_1)+\dots+\V (X_n) \big)
\\
&=
\frac{1}{n^2} \cdot n \sigma^2
\\
&=
\frac{\sigma^2}{n}
.
\end{align}

Usando a Desigualdade de Chebyshev, obtemos:
\begin{align}
\Pb\Big( \mu-a \leq \tfrac{X_1+\dots+X_n}{n} \leq \mu+a \Big)
&
=
1 - \Pb\Big( \Big|\frac{X_1+\dots+X_n}{n} - \mu \Big| > a \Big)
\\
&
\geq
1 - \frac{\V(\frac{X_1+\dots+X_n}{n})}{a^2}
\\
&
=
1 - \frac{\sigma^2}{a^2 \cdot n}
,
\end{align}
o que conclui a prova.
